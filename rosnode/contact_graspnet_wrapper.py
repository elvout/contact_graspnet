import os
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional

import numpy as np

# Set TensorFlow's log level to WARNING to reduce log spam. Wrapping this logic
# in an `if True` silences flake8's E402.
if True:
    # https://stackoverflow.com/a/38873777
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
import tensorflow.compat.v1 as tf  # type: ignore

# Hijack sys.path because contact_graspnet is written using relative imports
# (despite having an __init__.py). Wrapping this logic in an `if True` silences
# flake8's E402.
if True:
    PROJECT_ROOT_DIR = Path(__file__).parent.parent
    sys.path.append(str(PROJECT_ROOT_DIR / "contact_graspnet"))

import contact_graspnet.config_utils
import contact_graspnet.visualization_utils
from contact_graspnet.contact_grasp_estimator import GraspEstimator

# Set up tensorflow options.
# Copied from contact_graspnet/inference.py
tf.disable_eager_execution()
# These two lines cause pytorch to crash
# physical_devices = tf.config.experimental.list_physical_devices("GPU")
# tf.config.experimental.set_memory_growth(physical_devices[0], True)


@dataclass
class ContactGraspnetParams:
    ckpt_dir: str = field(default="checkpoints/scene_test_2048_bs3_hor_sigma_001")
    z_range: list[float] = field(default_factory=lambda: [0.2, 1.8])
    """Z value threshold to croup to input point cloud."""

    local_regions: bool = field(default=False)
    """Whether to crop 3D local regions around given segments."""

    filter_grasps: bool = field(default=False)
    """Whether to filter grasp contacts according to segmentation maps."""

    skip_border_objects: bool = field(default=False)
    """Whether to ignore segments at the depth map boundary when extracting
    local regions."""

    forward_passes: int = field(default=1)
    """Number of parallel forward passes to run in mesh_utils for more potential
    contact points."""

    segmap_id: int = field(default=0)
    """Only return grasps with the given segment id (0 = all)."""

    visualize_grasps: bool = field(default=False)
    """Whether to generate grasp visualization images."""


class ContactGraspnetWrapper:
    @dataclass
    class ModelOutput:
        pred_grasps_cam: dict[int, np.ndarray] = field(default_factory=dict)
        """
        k: segment id
        v: 3D poses; ndarray of shape (n_grasps, 4, 4)
        """

        scores: dict[int, np.ndarray] = field(default_factory=dict)
        """
        k: segment id
        v: unsorted ndarray of shape (n_grasps,)
        """

        vis_image: Optional[np.ndarray] = field(default=None)
        """
        Visualization image generated by contact_graspnet utils.
        """

    def __init__(self, params: ContactGraspnetParams) -> None:
        self._params = params

        # Build the model
        contact_graspnet_config = contact_graspnet.config_utils.load_config(
            self._params.ckpt_dir,
            batch_size=self._params.forward_passes,
            arg_configs=[],
        )
        self._grasp_estimator = GraspEstimator(contact_graspnet_config)
        self._grasp_estimator.build_network()

        # Add ops to save and restore all the variables.
        self._tf_saver = tf.train.Saver(save_relative_paths=True)

        # Create a session
        tf_config = tf.ConfigProto()
        tf_config.gpu_options.allow_growth = True
        tf_config.allow_soft_placement = True
        self._tf_session = tf.Session(config=tf_config)

        # Load weights
        self._grasp_estimator.load_weights(
            self._tf_session, self._tf_saver, self._params.ckpt_dir, mode="test"
        )

    def forward(
        self,
        rgb_image: np.ndarray,
        depth_image: np.ndarray,
        intrinsic_matrix: np.ndarray,
        segmap_image: Optional[np.ndarray] = None,
    ) -> ModelOutput:
        """
        Arguments:
            rgb_image: HxWx3 uint8 image
            depth_image: HxW float32 image (depth values in meters)
            intrinsic_matrix: 3x3 matrix
            segmap_image: HxW uint8 image
        """
        # Convert depth to point clouds
        pc_full, pc_segments, pc_colors = self._grasp_estimator.extract_point_clouds(
            depth_image,
            intrinsic_matrix,
            segmap=segmap_image,
            rgb=rgb_image,
            z_range=self._params.z_range,
            skip_border_objects=self._params.skip_border_objects,
        )

        # Generate grasps
        output = self.ModelOutput()
        try:
            (
                output.pred_grasps_cam,
                output.scores,
                contact_pts,
                gripper_openings,
            ) = self._grasp_estimator.predict_scene_grasps(
                self._tf_session,
                pc_full,
                pc_segments=pc_segments,
                local_regions=self._params.local_regions,
                filter_grasps=self._params.filter_grasps,
                verbose=False,
            )
        except ValueError:
            """Occasionally the prediction function throws an error:

              File "/contact_graspnet/contact_graspnet/contact_grasp_estimator.py", line ..., in predict_scene_grasps
                pc_full = regularize_pc_point_count(pc_full, self._contact_grasp_cfg['DATA']['raw_num_points'])
              File "/contact_graspnet/contact_graspnet/data.py", line ..., in regularize_pc_point_count
                index = np.random.choice(range(pc.shape[0]), size=required)
              File "mtrand.pyx", line 908, in numpy.random.mtrand.RandomState.choice
            ValueError: 'a' cannot be empty unless no samples are taken
            """
            return output

        if self._params.visualize_grasps:
            vis_image = contact_graspnet.visualization_utils.visualize_grasps(
                pc_full,
                output.pred_grasps_cam,
                output.scores,
                plot_opencv_cam=True,
                pc_colors=pc_colors,
                interactive=False,
            )

            # rotate the image clockwise
            output.vis_image = np.rot90(vis_image, axes=(1, 0))

        return output
